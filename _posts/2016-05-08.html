<!DOCTYPE html>
<html>
<head>
<title>Into the Backpropagation Algorithm</title>
</head>
<body>

<h1>Into the Backpropagation Algorithm</h1>
<p>The backpropagation algorithm has two parts, the Forward-Propagation and the Backpropagation. Forward-Propagation is the first half of Backpropagation that is used to find the loss of the neural network. The loss could be called an error because it shows the magnitude of error that our neural network outputs. </p>

<p>This error is calculated by multiplying our weights with our input and passing the product of these vectors to our activation function.  The activation function is just supposed to take in the array of numbers and squish those number between the ranges of those activation function. This number is then stored in a hidden neural layer. It is used to calculate the loss (error) by subtracting the output from the values of the hidden neural layer (The number that our activation returned)</p>
<p>The second half of this algorithm is Backpropagation. Backpropagation is moving backwards on the network and (as far as I know right now), we multiply the hidden neural layer by the gradient of the state of what our weights are in. Once this is done, we change the weights to the dot product of our input array and the gradient of what we calculated during our Forward propagation (the second layer of the network, on a two layer network). Backpropagation is a heavy subject, so Iâ€™ll be spending more time studying it.</p>
</p>

</body>
</html>
